{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the raw data directory (system agnostic)\n",
    "data_dir = os.path.join(os.getcwd(), 'data', 'raw')\n",
    "\n",
    "#create a dictionary to store the raw file names by metric\n",
    "data_dict = {'median_home_value': [],\n",
    "             'median_income': [],\n",
    "             'education_attained': []}\n",
    "\n",
    "#assign each file to the appropriate metric\n",
    "for raw_file in os.listdir(data_dir):\n",
    "    if 'B25077' in raw_file:\n",
    "        data_dict['median_home_value'].append(os.path.join(data_dir, raw_file))\n",
    "    elif 'S1903' in raw_file:\n",
    "        data_dict['median_income'].append(os.path.join(data_dir, raw_file))\n",
    "    elif 'S1501' in raw_file:\n",
    "        data_dict['education_attained'].append(os.path.join(data_dir, raw_file))\n",
    "    else:\n",
    "        print('Unexpected data file {} - skipping'.format(raw_file))\n",
    "\n",
    "#they should aready be sorted but just in case\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = sorted(data_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are all the zip codes in the Austin metroplex\n",
    "austin_zips = [78610, 78613, 78617, 78641, 78652, 78653, 78660, 78664, 78681, 78701, \n",
    "               78702, 78703, 78704, 78705, 78712, 78717, 78719, 78721, 78722, 78723, \n",
    "               78724, 78725, 78726, 78727, 78728, 78729, 78730, 78731, 78732, 78733, \n",
    "               78734, 78735, 78736, 78737, 78738, 78739, 78741, 78742, 78744, 78745, \n",
    "               78746, 78747, 78748, 78749, 78750, 78751, 78752, 78753, 78754, 78756, \n",
    "               78757, 78758, 78759]\n",
    "\n",
    "#the area in the zip code 78712 is all part of the University of Texas (aka \"The 40 Acres\")\n",
    "#there is no data for median home value or median income in this zip code so I'm excluding it\n",
    "#from this study\n",
    "austin_zips.remove(78712)\n",
    "\n",
    "#create a list of years which will be used to parse the data\n",
    "years = [2011, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "#the education attained dataframe with have multi-indexed columns\n",
    "#the column will be years and the subcolumns are created below\n",
    "sub_col = ['<9th', '9th-12th', 'high_school', 'some_college', \n",
    "           'associate', 'bachelor', 'graduate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create blank dataframes for each dataset\n",
    "median_home_value = pd.DataFrame(index=austin_zips, columns=years)\n",
    "median_income = pd.DataFrame(index=austin_zips, columns=years)\n",
    "education_attained = pd.DataFrame(index=austin_zips, columns=pd.MultiIndex.from_product([years, sub_col]))\n",
    "\n",
    "#iterate through enumerated years\n",
    "for i, year in enumerate(years):\n",
    "    #read the appropriate median home value and median income raw data and assign it to the proper year\n",
    "    median_home_value[year] = pd.read_csv(data_dict['median_home_value'][i], skiprows=2, usecols=[1, 3],\n",
    "                                          index_col=0).loc[austin_zips].astype('float')\n",
    "    median_income[year] = pd.read_csv(data_dict['median_income'][i], skiprows=2, usecols=[1, 5],\n",
    "                                      index_col=0).loc[austin_zips].astype('float')\n",
    "    #the education attained raw data for 2015 and 2016 is given as bulk counts whereas the raw\n",
    "    #data for 2011-2014 are given in percentages. I'll convert the 2015 and 2016 data to \n",
    "    #percentages so all the data has the same format\n",
    "    if year in [2015, 2016]:\n",
    "        #read the education obtained raw data (including total)\n",
    "        tmp = pd.read_csv(data_dict['education_attained'][-1], skiprows=2, \n",
    "                          usecols=[1, 13, 15, 17, 19, 21, 23, 25, 27], \n",
    "                          index_col=0, names=['zip', 'total']+sub_col).loc[austin_zips]\n",
    "        #convert each column to a percentage by dividing by the total and multiplying by 100\n",
    "        #I've rounded to the first decimal place for consistency with the 2011-2014 data\n",
    "        for col in tmp.columns[1:]:\n",
    "            tmp[col] = (tmp[col] / tmp['total'] * 100).round(1)\n",
    "        #remove the 'total' column\n",
    "        tmp = tmp[tmp.columns[1:]]\n",
    "        #assign the data to the appropriate year\n",
    "        education_attained[year] = tmp\n",
    "    else:\n",
    "        #if years 2011-2014, read the data and assign it to the appropriate year\n",
    "        education_attained[year] = pd.read_csv(data_dict['education_attained'][i], skiprows=2, \n",
    "                                               usecols=[1, 15, 17, 19, 21, 23, 25, 27], index_col=0,\n",
    "                                               names=['zip']+sub_col).loc[austin_zips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set path for saving processed data\n",
    "processed_data_dir = os.path.join(os.getcwd(), 'data', 'processed')\n",
    "#save each of the dataframes\n",
    "median_home_value.to_csv(os.path.join(processed_data_dir, 'median_home_value.csv'))\n",
    "median_income.to_csv(os.path.join(processed_data_dir, 'median_income.csv'))\n",
    "education_attained.to_csv(os.path.join(processed_data_dir, 'education_attained.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
