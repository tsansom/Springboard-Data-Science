{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read offense data\n",
    "offense = pd.read_csv('data/offense.csv')\n",
    "# read defense data\n",
    "defense = pd.read_csv('data/defense.csv')\n",
    "# read salary data\n",
    "salary = pd.read_csv('data/salary.csv', index_col=0)\n",
    "# change columns (uppercase first letter) to match the other data\n",
    "salary.columns = ['Team', 'Year'] + list(salary.columns[2:])\n",
    "# read standings data\n",
    "standings = pd.read_csv('data/standings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to fix the offense and defense stats so that they are the previous year. Can do this by adding 1 to the year before merging the datasets. Salary is known at the beginning of the season so the year doesn't have to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense['Year'] += 1\n",
    "defense['Year'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the offense and defense data with suffixes\n",
    "combined = pd.merge(offense, defense, on=['Team', 'Year'], suffixes=('_off', '_def'))\n",
    "# merge the salary data\n",
    "combined = pd.merge(combined, salary, on=['Team', 'Year'])\n",
    "# merge the standings dataframe - use left so 2018 data stays\n",
    "combined = pd.merge(combined, standings, on=['Team', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the X and y from combined\n",
    "X_all = combined[combined.columns[:-8]].copy()\n",
    "y_all = combined[combined.columns[-8:]].copy()\n",
    "\n",
    "# add team and year back into y\n",
    "y_all.insert(0, 'Team', X_all['Team'])\n",
    "y_all.insert(1, 'Year', X_all['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'SB_win'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_all.merge(y_all[['Team', 'Year', target_var]])\n",
    "\n",
    "data_future = data[data['Year'] == 2018]\n",
    "\n",
    "data = data[data['Year'] < 2018]\n",
    "\n",
    "features = data.columns[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000    155\n",
       "1.0000      5\n",
       "Name: SB_win, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[target_var].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEg1JREFUeJzt3Xu0pXVdx/H3R0YxMwOcA+EM05CNFrks6URoWSRdwMxhlbpweZmUOll46eLykn/QquVauirNS2mTIEMLUSKLWWUXIoluYAdEBJGcsOAEOodQzCxopm9/7AdnO/xmzmY4z36O7Pdrrb328/ye336e71lrr/nM77n8dqoKSZL297ChC5AkrU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElN6/racZLzgGcBu6vqSWPtrwBeDuwB/rSqXtO1vx44C9gLvLKq/mKlY6xfv742b97cQ/WS9NB1zTXX3FlVcyv16y0ggPOBdwIX3NeQ5AeArcCTq+qeJEd37ScAZwLfBjwO+KskT6iqvQc7wObNm1lcXOypfEl6aEryb5P06+0UU1VdCdy1X/PPAm+qqnu6Pru79q3A+6vqnqr6NLALOKmv2iRJK5v2NYgnAE9PcnWSv0nyXV37BuC2sX5LXZskaSB9nmI60PGOBE4Gvgu4OMk3AWn0bU4zm2QBWADYtGlTT2VKkqY9glgCPlgjHwH+D1jftR831m8jcHtrB1W1varmq2p+bm7FayySpEM07YD4Y+AZAEmeADwCuBPYCZyZ5PAkxwNbgI9MuTZJ0pg+b3O9CDgFWJ9kCTgHOA84L8kNwL3Athr9YtGNSS4GPsHo9tezV7qDSZLUr3w1/6Lc/Px8eZurJD0wSa6pqvmV+vkktSSpyYCQJDVN+zbXNWfxlS8bugStQfNvf/fQJUiDcwQhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmnoLiCTnJdnd/f70/ttenaSSrO/Wk+TtSXYluT7JiX3VJUmaTJ8jiPOB0/ZvTHIc8EPArWPNpwNbutcC8K4e65IkTaC3gKiqK4G7GpveCrwGqLG2rcAFNXIVcESSY/uqTZK0sqleg0jybODfq+pj+23aANw2tr7UtUmSBjK136RO8ijgDcAPtzY32qrRRpIFRqeh2LRp06rVJ0n6StMcQTweOB74WJJ/BTYC1yb5BkYjhuPG+m4Ebm/tpKq2V9V8Vc3Pzc31XLIkza6pBURVfbyqjq6qzVW1mVEonFhVnwF2Ai/u7mY6Gbi7qu6YVm2SpPvr8zbXi4B/BJ6YZCnJWQfp/iHgFmAX8HvAz/VVlyRpMr1dg6iq56+wffPYcgFn91WLJOmB80lqSVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlq6vM3qc9LsjvJDWNtv57kk0muT/JHSY4Y2/b6JLuS3JzkR/qqS5I0mT5HEOcDp+3XdhnwpKp6MvDPwOsBkpwAnAl8W/eZ30lyWI+1SZJW0FtAVNWVwF37tf1lVe3pVq8CNnbLW4H3V9U9VfVpYBdwUl+1SZJWNuQ1iJcCf9YtbwBuG9u21LVJkgYySEAkeQOwB7jwvqZGtzrAZxeSLCZZXF5e7qtESZp5Uw+IJNuAZwEvqKr7QmAJOG6s20bg9tbnq2p7Vc1X1fzc3Fy/xUrSDJtqQCQ5DXgt8Oyq+tLYpp3AmUkOT3I8sAX4yDRrkyR9pXV97TjJRcApwPokS8A5jO5aOhy4LAnAVVX1sqq6McnFwCcYnXo6u6r29lWbJGllvQVEVT2/0XzuQfq/EXhjX/VIkh4Yn6SWJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqSm3gIiyXlJdie5YaztqCSXJflU935k154kb0+yK8n1SU7sqy5J0mT6HEGcD5y2X9vrgMuragtwebcOcDqwpXstAO/qsS5J0gR6C4iquhK4a7/mrcCObnkHcMZY+wU1chVwRJJj+6pNkrSyaV+DOKaq7gDo3o/u2jcAt431W+ra7ifJQpLFJIvLy8u9FitJs2ytXKROo61aHatqe1XNV9X83Nxcz2VJ0uyadkB89r5TR9377q59CThurN9G4PYp1yZJGjPtgNgJbOuWtwGXjrW/uLub6WTg7vtORUmShrGurx0nuQg4BVifZAk4B3gTcHGSs4Bbged23T8EPBPYBXwJeElfdUmSJtNbQFTV8w+w6dRG3wLO7qsWSdIDt1YuUkuS1hgDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKlpooBIcvkkbZKkh46DPiiX5JHAoxg9DX0k+ybVewzwuJ5rkyQNaKUnqX8G+HlGYXAN+wLiC8Bv91iXJGlgBw2Iqnob8LYkr6iqd0ypJknSGjDRXExV9Y4kTwM2j3+mqi7oqS5J0sAmCogkvw88HrgO2Ns1F2BASNJD1KSzuc4DJ3SzrkqSZsCkz0HcAHxDn4VIktaWSUcQ64FPJPkIcM99jVX17F6qkiQNbtKA+JU+i5AkrT2T3sX0N6t50CS/APwUowvdH2f0E6PHAu8HjgKuBV5UVfeu5nElSZObdKqN/0zyhe71P0n2JvnCoRwwyQbglcB8VT0JOAw4E3gz8Naq2gJ8DjjrUPYvSVodEwVEVX1dVT2mez0S+AngnQ/iuOuAr0myjtFUHncAzwAu6bbvAM54EPuXJD1IhzSba1X9MaN/0A/ls/8O/AZwK6NguJvRNB6fr6o9XbclYMOh7F+StDomfVDux8dWH8bouYhDeiaim/RvK3A88HngD4DTG12b+0+yACwAbNq06VBKkCRNYNK7mH5sbHkP8K+M/pE/FD8IfLqqlgGSfBB4GnBEknXdKGIjcHvrw1W1HdgOMD8/74N7ktSTSe9ieskqHvNW4OQkjwL+GzgVWAQ+DDyH0Z1M24BLV/GYkqQHaNK7mDYm+aMku5N8NskfJtl4KAesqqsZXYy+ltEtrg9jNCJ4LfCLSXYBjwXOPZT9S5JWx6SnmN4LvA94brf+wq7thw7loFV1DnDOfs23ACcdyv4kSatv0ruY5qrqvVW1p3udD8z1WJckaWCTBsSdSV6Y5LDu9ULgP/osTJI0rEkD4qXA84DPMHp24TmMpseQJD1ETXoN4teAbVX1OYAkRzF62O2lfRUmSRrWpCOIJ98XDgBVdRfwlH5KkiStBZMGxMO6J6CBL48gJh19SJK+Ck36j/xvAv+Q5BJGU2A8D3hjb1VJkgY36ZPUFyRZZDRBX4Afr6pP9FqZJGlQE58m6gLBUJCkGXFI031Lkh76DAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgYJiCRHJLkkySeT3JTkqUmOSnJZkk9170euvCdJUl+GGkG8DfjzqvoW4NuBm4DXAZdX1Rbg8m5dkjSQqQdEkscA3wecC1BV91bV54GtwI6u2w7gjGnXJknaZ4gRxDcBy8B7k3w0yXuSfC1wTFXdAdC9Hz1AbZKkzhABsQ44EXhXVT0F+C8ewOmkJAtJFpMsLi8v91WjJM28IQJiCViqqqu79UsYBcZnkxwL0L3vbn24qrZX1XxVzc/NzU2lYEmaRVMPiKr6DHBbkid2Tacy+p2JncC2rm0bcOm0a5Mk7TPU70q/ArgwySOAW4CXMAqri5OcBdwKPHeg2iRJDBQQVXUdMN/YdOq0a5EktfkktSSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNQ0WEEkOS/LRJH/SrR+f5Ookn0ryge73qiVJAxlyBPEq4Kax9TcDb62qLcDngLMGqUqSBAwUEEk2Aj8KvKdbD/AM4JKuyw7gjCFqkySNDDWC+C3gNcD/deuPBT5fVXu69SVgQ+uDSRaSLCZZXF5e7r9SSZpRUw+IJM8CdlfVNePNja7V+nxVba+q+aqan5ub66VGSRKsG+CY3wM8O8kzgUcCj2E0ojgiybpuFLERuH2A2iRJnamPIKrq9VW1sao2A2cCf11VLwA+DDyn67YNuHTatUmS9llLz0G8FvjFJLsYXZM4d+B6JGmmDXGK6cuq6grgim75FuCkIeuRJO2zlkYQkqQ1xICQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKlp6gGR5LgkH05yU5Ibk7yqaz8qyWVJPtW9Hznt2iRJ+wwxgtgD/FJVfStwMnB2khOA1wGXV9UW4PJuXZI0kKkHRFXdUVXXdsv/CdwEbAC2Aju6bjuAM6ZdmyRpn0GvQSTZDDwFuBo4pqrugFGIAEcPV5kkabCASPJo4A+Bn6+qLzyAzy0kWUyyuLy83F+BkjTjBgmIJA9nFA4XVtUHu+bPJjm2234ssLv12araXlXzVTU/Nzc3nYIlaQYNcRdTgHOBm6rqLWObdgLbuuVtwKXTrk2StM+6AY75PcCLgI8nua5r+2XgTcDFSc4CbgWeO0BtkqTO1AOiqv4OyAE2nzrNWiRJB+aT1JKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKlpiB8MkjSBl/3D4tAlaA1699Pmp3YsRxCSpCYDQpLUtOYCIslpSW5OsivJ64auR5Jm1ZoKiCSHAb8NnA6cADw/yQnDViVJs2lNBQRwErCrqm6pqnuB9wNbB65JkmbSWguIDcBtY+tLXZskacrW2m2uabTVV3RIFoCFbvWLSW7uvarZsR64c+gi1oR3/O7QFegr+d3srNI38xsn6bTWAmIJOG5sfSNw+3iHqtoObJ9mUbMiyWJVTe8ma2lCfjeHsdZOMf0TsCXJ8UkeAZwJ7By4JkmaSWtqBFFVe5K8HPgL4DDgvKq6ceCyJGkmramAAKiqDwEfGrqOGeWpO61VfjcHkKpauZckaeastWsQkqQ1woCYQStNZ5Lk8CQf6LZfnWTz9KvUrElyXpLdSW44wPYkeXv3vbw+yYnTrnHWGBAzZsLpTM4CPldV3wy8FXjzdKvUjDofOO0g208HtnSvBeBdU6hpphkQs2eS6Uy2Aju65UuAU5O0HmKUVk1VXQncdZAuW4ELauQq4Igkx06nutlkQMyeSaYz+XKfqtoD3A08dirVSQfmVDxTZkDMnhWnM5mwjzRtfi+nzICYPStOZzLeJ8k64Os5+NBfmoZJvrtaRQbE7JlkOpOdwLZu+TnAX5cPzGh4O4EXd3cznQzcXVV3DF3UQ9mae5Ja/TrQdCZJfhVYrKqdwLnA7yfZxWjkcOZwFWtWJLkIOAVYn2QJOAd4OEBVvZvRDAvPBHYBXwJeMkyls8MnqSVJTZ5ikiQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyIKSGJG9IcmM3rfR1Sb47yRXdNOnXJbkpycKDPMZ7GjPpSmuGz0FI+0nyVOAtwClVdU+S9cAjgPcBr66qxSRHAf8CHNPNiis95DiCkO7vWODOqroHoKrurKr95/x5NPBfwN7WDpI8L8lbuuVXJbmlW358kr/rlq9IMt8tfzHJG5N8LMlVSY7p50+TJmdASPf3l8BxSf45ye8k+f6xbRcmuR64Gfi1qmoGBHAl8PRu+enAfyTZAHwv8LeN/l8LXFVV39599qdX4w+RHgwDQtpPVX0R+E5Gv1q2DHwgyU92m19QVU8GNgGvTvKNB9jHZ4BHJ/k6RjOQvg/4PkZh0QqIe4E/6ZavATavyh8jPQgGhNRQVXur6oqqOgd4OfAT+21fBq4Fvvsgu/lHRhPK3cwoFJ4OPBX4+0bf/x2bMXcvTqSpNcCAkPaT5IlJtow1fQfwb/v1eRTwFEYXqg/kSuDV3ftHgR8A7qmqu1e3Yqkf/i9Fur9HA+9IcgSwh9H00guMfp/7wiT/DRwOnF9V1xxkP3/L6PTSlVW1N8ltwCf7LV1aPd7mKklq8hSTJKnJU0zSg5TkakannMa9qKo+PkQ90mrxFJMkqclTTJKkJgNCktRkQEiSmgwISVKTASFJavp/FE6hlo77xa0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x=target_var, data=data, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SB_win</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>2015.0000</td>\n",
       "      <td>2015.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yds/G_rush_off</th>\n",
       "      <td>111.2871</td>\n",
       "      <td>120.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_rush_off</th>\n",
       "      <td>12.3806</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yds/G_pass_off</th>\n",
       "      <td>237.4265</td>\n",
       "      <td>249.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_off</th>\n",
       "      <td>62.0613</td>\n",
       "      <td>63.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_pass_off</th>\n",
       "      <td>24.8516</td>\n",
       "      <td>28.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sck_off</th>\n",
       "      <td>37.5484</td>\n",
       "      <td>32.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rate_off</th>\n",
       "      <td>87.7994</td>\n",
       "      <td>94.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pts/G_off</th>\n",
       "      <td>22.7284</td>\n",
       "      <td>27.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pen Yds_off</th>\n",
       "      <td>891.0903</td>\n",
       "      <td>872.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>-0.2581</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yds/G_rush_def</th>\n",
       "      <td>111.8258</td>\n",
       "      <td>103.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_rush_def</th>\n",
       "      <td>12.6000</td>\n",
       "      <td>9.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yds/G_pass_def</th>\n",
       "      <td>238.0690</td>\n",
       "      <td>229.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_pass_def</th>\n",
       "      <td>25.0194</td>\n",
       "      <td>23.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rate_def</th>\n",
       "      <td>88.3671</td>\n",
       "      <td>81.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sck_def</th>\n",
       "      <td>37.2452</td>\n",
       "      <td>41.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_def</th>\n",
       "      <td>62.2497</td>\n",
       "      <td>59.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pts/G_def</th>\n",
       "      <td>22.9710</td>\n",
       "      <td>19.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pen Yds_def</th>\n",
       "      <td>890.0903</td>\n",
       "      <td>903.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>20300676.3613</td>\n",
       "      <td>19734611.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>17411399.2387</td>\n",
       "      <td>17737363.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OL</th>\n",
       "      <td>21920389.9355</td>\n",
       "      <td>25394425.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QB</th>\n",
       "      <td>13470135.1097</td>\n",
       "      <td>11843176.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RB</th>\n",
       "      <td>6296500.6000</td>\n",
       "      <td>5588751.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>21532991.5161</td>\n",
       "      <td>19397923.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>4201099.4129</td>\n",
       "      <td>4245629.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TE</th>\n",
       "      <td>6312189.9871</td>\n",
       "      <td>9958081.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WR</th>\n",
       "      <td>13630506.7484</td>\n",
       "      <td>18144781.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nDL</th>\n",
       "      <td>9.4839</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nLB</th>\n",
       "      <td>9.5613</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nOL</th>\n",
       "      <td>10.9355</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nQB</th>\n",
       "      <td>2.9548</td>\n",
       "      <td>2.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nRB</th>\n",
       "      <td>4.7032</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nS</th>\n",
       "      <td>12.1290</td>\n",
       "      <td>11.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nST</th>\n",
       "      <td>3.2516</td>\n",
       "      <td>3.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nTE</th>\n",
       "      <td>4.1548</td>\n",
       "      <td>3.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nWR</th>\n",
       "      <td>7.2323</td>\n",
       "      <td>7.2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SB_win                0.0000        1.0000\n",
       "Year               2015.0000     2015.0000\n",
       "Yds/G_rush_off      111.2871      120.6000\n",
       "TD_rush_off          12.3806       16.0000\n",
       "Yds/G_pass_off      237.4265      249.3800\n",
       "Pct_off              62.0613       63.3600\n",
       "TD_pass_off          24.8516       28.8000\n",
       "Sck_off              37.5484       32.2000\n",
       "Rate_off             87.7994       94.0600\n",
       "Pts/G_off            22.7284       27.1400\n",
       "Pen Yds_off         891.0903      872.8000\n",
       "TO                   -0.2581        8.0000\n",
       "Yds/G_rush_def      111.8258      103.8000\n",
       "TD_rush_def          12.6000        9.2000\n",
       "Yds/G_pass_def      238.0690      229.5400\n",
       "TD_pass_def          25.0194       23.6000\n",
       "Rate_def             88.3671       81.5800\n",
       "Sck_def              37.2452       41.6000\n",
       "Pct_def              62.2497       59.6000\n",
       "Pts/G_def            22.9710       19.7800\n",
       "Pen Yds_def         890.0903      903.8000\n",
       "DL             20300676.3613 19734611.8000\n",
       "LB             17411399.2387 17737363.6000\n",
       "OL             21920389.9355 25394425.6000\n",
       "QB             13470135.1097 11843176.0000\n",
       "RB              6296500.6000  5588751.2000\n",
       "S              21532991.5161 19397923.2000\n",
       "ST              4201099.4129  4245629.4000\n",
       "TE              6312189.9871  9958081.6000\n",
       "WR             13630506.7484 18144781.6000\n",
       "nDL                   9.4839        9.0000\n",
       "nLB                   9.5613        9.0000\n",
       "nOL                  10.9355       10.0000\n",
       "nQB                   2.9548        2.6000\n",
       "nRB                   4.7032        5.0000\n",
       "nS                   12.1290       11.4000\n",
       "nST                   3.2516        3.2000\n",
       "nTE                   4.1548        3.4000\n",
       "nWR                   7.2323        7.2000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(target_var).mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features]\n",
    "y = data[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X[data['Year'] == 2017]\n",
    "y_valid = y[data['Year'] == 2017]\n",
    "\n",
    "X = X.loc[data['Year'] < 2017]\n",
    "y = y.loc[data['Year'] < 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.87      0.92        31\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.93      0.84      0.89        32\n",
      "\n",
      "[[27  4]\n",
      " [ 1  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X, y)\n",
    "\n",
    "y_pred = logit.predict(X_valid)\n",
    "y_proba = logit.predict_proba(X_valid)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.34697512, 0.65302488],\n",
       "        [0.20252433, 0.79747567],\n",
       "        [0.84883214, 0.15116786],\n",
       "        [0.98635006, 0.01364994],\n",
       "        [0.52695525, 0.47304475],\n",
       "        [0.49060612, 0.50939388],\n",
       "        [0.48369039, 0.51630961],\n",
       "        [0.93001284, 0.06998716],\n",
       "        [0.98543645, 0.01456355],\n",
       "        [0.79056578, 0.20943422],\n",
       "        [0.69386081, 0.30613919],\n",
       "        [0.99764423, 0.00235577],\n",
       "        [0.81034566, 0.18965434],\n",
       "        [0.89678478, 0.10321522],\n",
       "        [0.98098133, 0.01901867],\n",
       "        [0.94847963, 0.05152037],\n",
       "        [0.94084618, 0.05915382],\n",
       "        [0.66886486, 0.33113514],\n",
       "        [0.99522845, 0.00477155],\n",
       "        [0.84313466, 0.15686534],\n",
       "        [0.77555299, 0.22444701],\n",
       "        [0.93021552, 0.06978448],\n",
       "        [0.96505531, 0.03494469],\n",
       "        [0.99077669, 0.00922331],\n",
       "        [0.97510619, 0.02489381],\n",
       "        [0.91648874, 0.08351126],\n",
       "        [0.9071288 , 0.0928712 ],\n",
       "        [0.98086226, 0.01913774],\n",
       "        [0.99018627, 0.00981373],\n",
       "        [0.98204481, 0.01795519],\n",
       "        [0.98983321, 0.01016679],\n",
       "        [0.98056954, 0.01943046]]), 128    BUF\n",
       " 129    DAL\n",
       " 130    TEN\n",
       " 131     SF\n",
       " 132    ATL\n",
       " 133    OAK\n",
       " 134     NE\n",
       " 135    HOU\n",
       " 136    MIA\n",
       " 137    CAR\n",
       " 138    PHI\n",
       " 139    NYJ\n",
       " 140    CIN\n",
       " 141    PIT\n",
       " 142     KC\n",
       " 143     NO\n",
       " 144    CHI\n",
       " 145    ARI\n",
       " 146    CLE\n",
       " 147     GB\n",
       " 148    WAS\n",
       " 149    JAC\n",
       " 150    IND\n",
       " 151     TB\n",
       " 152    SEA\n",
       " 153    LAC\n",
       " 154    DEN\n",
       " 155    BAL\n",
       " 156    NYG\n",
       " 157    DET\n",
       " 158     LA\n",
       " 159    MIN\n",
       " Name: Team, dtype: object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba, data[data['Year'] == 2017]['Team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98        31\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.94      0.97      0.95        32\n",
      "\n",
      "[[31  0]\n",
      " [ 1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsansom/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X, y)\n",
    "\n",
    "y_pred = svc.predict(X_valid)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98        31\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.94      0.97      0.95        32\n",
      "\n",
      "[[31  0]\n",
      " [ 1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsansom/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X, y)\n",
    "\n",
    "y_pred = svc.predict(X_valid)\n",
    "\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
